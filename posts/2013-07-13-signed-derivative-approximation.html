<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Warwick Masson - The Signed Derivative Approximation</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
	<link rel="stylesheet" type="text/css" href="../css/syntax.css" />
        <link rel="alternate" type="application/rss+xml" title="Blog" href="../rss.xml" />
    </head>
    <body>
        <h1><div id="title"><span class="rounded">Warwick Masson</span></div></h1>
        <div id="navigation">
            <p><a href="../" class="rounded">Home</a></p>
            <p><a href="../posts.html" class="rounded">Posts</a></p>
	    <p><a href="../tags.html" class="rounded">Tags</a></p>
            <p><a href="../about.html" class="rounded">About</a></p>
	    <p><a href="../rss.xml" class="rounded">RSS</a></p>
        </div>
        <div id="content"><h2>The Signed Derivative Approximation</h2>

<p>On <strong>July 13, 2013</strong></p>

<p>Policy gradient methods are a powerful class of methods for learning robot control. The idea is that for control problems which involve finding a parameterized control policy, we can optimize the policy by performing gradient descent on those parameters.</p>
<h4 id="gradient-descent">Gradient Descent</h4>
<p>Gradient descent is a simple method for finding a minima for a function. Suppose we have a function f and we want to find x which minimizes f(x). We can find such an x, by starting at some x0 and repeatedly moving in the direction of steepest descent. The direction of steepest descent is the gradient of the function f.</p>
<h4 id="policy-gradients">Policy Gradients</h4>
<p>In robotics, we often want to minimize some cost function. An example of this would be to minimize the error achieved when following some trajectory. If possible, we’d like to find the parameters that will allow us to follow a trajectory precisely. Policy gradient methods achieve this by applying gradient descent to find such parameters. The main problem in policy gradient research is to compute the gradient so we can use gradient descent. For a good overview of policy gradient methods, have a look at Jan Peter’s <a href="http:www.scholarpedia.org/article/Policy_Gradient_Methods">article on policy gradient methods</a>.</p>
<h4 id="the-signed-derivative-approximation">The Signed Derivative Approximation</h4>
<p>In order to compute the gradient we wish to descend, one method is to compute it directly. Kolter and Ng showed this was possible with some knowledge of the model. Specifically, they showed that for a quadratic cost function, the gradient is computable using the Jacobian. The Jacobian gives the change in each state element with respect to a change in one of the controls. The signed derivative approximation works by replacing the Jacobian term with a single matrix consisting of only the signs of the dominant terms.</p>
<p>The PGSD algorithm uses the signed derivative to compute the gradient. Their paper on this can is available <a href="http://www.robotsproceedingsorg/rss05/p27.pdf">here</a>. The results using this algorithm are impressive, especially given the simplicity of the signed derivative.</p>
<h4 id="current-work">Current Work</h4>
<p>For my honour’s thesis, I’m looking at learning the signed derivative actively by interacting with the environment. I’m planning the experimentally verify the results using the <a href="ardrone.parrot.com">Ar.Drone</a>.</p>

<p>Tags: <a href="../tags/policy gradients.html">policy gradients</a>, <a href="../tags/robotics.html">robotics</a>.</p>
</div>
        <div id="footer">
            <p>This site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a>.
            Background by <a href="http://subtlepatterns.com/cubes">Sander Ottens</a>.</p>
        </div>
    </body>
    <script type="text/javascript">

</script>
</html>
